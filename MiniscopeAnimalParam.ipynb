{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##    <font color='green'> STOP 1</font>    <font color='red'>       Please enter the path to the session data :</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   <font color='red'> ____________________________________________________________</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session =  r\"\\\\iss\\karalis\\users\\nikolas.karalis\\Data\\FMI\\Neuromod\\nk50\\nk50_s05_fc_ext\\19_35_46\\My_V4_Miniscope\"    # this is where you should store your dataset of videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   <font color='red'> ____________________________________________________________</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THIS IS FOR RUNNING WITHOUT PARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from termcolor import colored\n",
    "\n",
    "\n",
    "# Get the flag from the environment variable\n",
    "interactive = False\n",
    "\n",
    "dpath = os.getenv(\"SESSION_PATH\", \"\")\n",
    "if not dpath :\n",
    "    dpath = session\n",
    "    interactive = True\n",
    "\n",
    "\n",
    "with open(\"CON\", \"w\") as terminal:\n",
    "    print(colored('Running for session : ', \"cyan\"), file = terminal )\n",
    "    print(colored(dpath, \"light_cyan\"), file = terminal )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a flag to skip the cell in non tuning mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magic import register_cell_magic\n",
    "\n",
    "SKIP_CELLS = not interactive\n",
    "\n",
    "@register_cell_magic\n",
    "def skip_cell(line, cell):\n",
    "    if not SKIP_CELLS:\n",
    "        exec(cell, globals())\n",
    "    else:\n",
    "        print(\"Skipping this cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "tutorial"
    ]
   },
   "source": [
    "## Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "tutorial"
    ]
   },
   "source": [
    "There are 5 main sections in this pipeline: Setting up, Pre-processing, Motion Correction, Initialization, and CNMF, which are composed of interative spatial update and temporal update.\n",
    "\n",
    "![workflow](img/workflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "print(\"Cell running\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import itertools as itt\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import json\n",
    "\n",
    "import holoviews as hv\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "#from dask_cuda import LocalCUDACluster\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from holoviews.operation.datashader import datashade, regrid\n",
    "from holoviews.util import Dynamic\n",
    "from IPython.core.display import display\n",
    "\n",
    "import dask\n",
    "dask.config.set({\"distributed.worker.memory.target\": 0.6})  # Reduce memory pressure\n",
    "dask.config.set({\"distributed.worker.memory.spill\": 0.7})   # Spill to disk before crashing\n",
    "dask.config.set({\"distributed.worker.memory.pause\": 0.8})   # Pause workers before they die\n",
    "dask.config.set({\"distributed.worker.memory.terminate\": 0.9})  # Kill workers only if extreme\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Suppress logs\n",
    "!ffmpeg -i input.mp4 output.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set path and parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "tutorial"
    ]
   },
   "source": [
    "Set all of the parameters that control the notebook’s behavior.\n",
    "Ideally, the following cell is the only part of the code the user will have to change when analyzing different datasets.\n",
    "Here we briefly introduce only some of the initial parameters that are necessary to start the pipeline, and leave the discussion of specific parameters for later.\n",
    "\n",
    "* `minian_path` is the path that contains the **minian** folder , where the minian codebase (.py files) reside.\n",
    "    The default value `\".\"` means “current folder”, which should work in most cases, unless you want to try out another version of minian that is not in the same folder as this notebook.\n",
    "\n",
    "* `dpath` is the folder that contains the videos to be processed.\n",
    "\n",
    "* `interactive` controls whether interactive plots will be shown for parameters exploration.\n",
    "    Interactive plotting requires CPU/memory usage, and thus could require some time (in particular, those steps where video is played).\n",
    "    In principle, the user might want to visualize interactive plots during the initial parameters exploration, once the parameters are set and ready for batch processing, the user will set interactive as False to reduce processing time.\n",
    "\n",
    "* `output_size` controls the relative size of all the plots on a scale of 0-100 percent, though it can be set to values >100 without any problem. \n",
    "\n",
    "* `param_save_minian` specifies the destination folder and format of the saved data.\n",
    "    `dpath` is the folder path  where  the data will be saved.\n",
    "    `meta_dict` is a `dictionary` that is used to construct meta data for the final labeled data structure.\n",
    "    `overwrite` is a boolean value controlling whether the data is overwritten if a file already exists.\n",
    "    We set it to `True` here so you can easily play with the demo multiple times, but **use caution** with this option during actual analysis.\n",
    "    In addition to erasing prior data that may be important to you, overwritting data may cause compatibility issues with existing data from the same minian dataset folder.\n",
    "    If you want to re-analyze a video from scratch using different parameters, it is recommended that you delete existing data first.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<strong>folder structure</strong>\n",
    "\n",
    "The defult `meta_dict` in `param_save_minian` assumes output minian datasets are stored in heirarchiically arranged folders, as shown below:\n",
    "\n",
    "```\n",
    "mice1  \n",
    "│\n",
    "└───session1\n",
    "│   │\n",
    "│   └───minian\n",
    "│       │   Y.zarr\n",
    "│       │   A.zarr\n",
    "│       │   ...\n",
    "│   \n",
    "└───session2\n",
    "    │\n",
    "    └───minian\n",
    "```\n",
    "\n",
    "The default value can be read as follows:\n",
    "The name of the last folder (`-1`) in `dpath` (the folder that directly contains the videos) will be used to designate the value of a metadata dimension named `\"session\"`.\n",
    "The name of the second-to-last folder (`-2`) in `dpath` will be used to designate the value for `\"animal\"` and so on.\n",
    "Both the keys (name of metadata dimension) and values (numbers indicating which level of folder name should be used) of `meta_dict` can be modified to represent your preferred way of data storage. \n",
    "Note that the metadata are determined by the folder structure of saved minian datasets, not by those of input movie data.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up Initial Basic Parameters#\n",
    "minian_path = \".\"\n",
    "mouse_name = re.search(r'nk[^\\\\]*', dpath).group(0)\n",
    "session_name = re.search(fr\"{mouse_name}_s.*?(?=\\\\)\", dpath).group(0)\n",
    "result_path = os.path.join(\"C:/Users/axelle.piguet/Documents/GitHub/klab_analysis/Axelle\"  , mouse_name) #this is for param file \n",
    "minian_ds_path = os.path.join(result_path, session_name, \"result\")\n",
    "#minian_ds_path = os.path.join(result_path, session_name)\n",
    "\n",
    "\n",
    "###################\n",
    "# Define the path to the parameters file\n",
    "param_file = os.path.join(result_path, \"minian_parameters.json\")\n",
    "\n",
    "# Initialize the parameters dictionary\n",
    "parameters = {}\n",
    "\n",
    "# Check if the file exists before loading\n",
    "if os.path.exists(param_file):\n",
    "    with open(param_file, \"r\") as file:\n",
    "        parameters = json.load(file)\n",
    "        print(colored(\"Parameters loaded successfully:\", \"green\"), file = open(\"CON\", \"w\") )\n",
    "        print(\"Parameters loaded successfully:\", parameters, file = open(\"CON\", \"w\"))\n",
    "        print(\"Parameters loaded successfully:\", parameters)\n",
    "    # interactive = False # might want to change that during analysis\n",
    "else:\n",
    "    print(colored(\"No parameters file found. Using default values\", \"green\"), file = open(\"CON\", \"w\") )\n",
    "    print(\"No parameters file found. Using default values\")\n",
    "    parameters = {\n",
    "    \"ksize\":9,#7,\n",
    "    \"wnd\": 15,\n",
    "    \"noise_freq\": 0.1,#0.06,\n",
    "    \"thres\": 0.5,# 1,\n",
    "    \"thres_dist\": 6,#10,\n",
    "    \"spatial_sparse_penal1\":0.01,\n",
    "    \"temp_sparse_penal1\": 0.5,#1,\n",
    "    \"spatial_sparse_penal2\": 0.01,\n",
    "    \"temp_sparse_penal2\": 0.5,#1\n",
    "    }\n",
    "    # interactive = True # might want to change that during analysis\n",
    "###################\n",
    "\n",
    "\n",
    "# ADD INPUT IN WHICH you choose if interactive\n",
    "\n",
    "\n",
    "\n",
    "intpath = \"./minian_intermediate\"\n",
    "subset = dict(frame=slice(0, None))\n",
    "\n",
    "#interactive = True # might want to change that during analysis\n",
    "output_size = 100 # zoom param \n",
    "n_workers = int(os.getenv(\"MINIAN_NWORKERS\", 4))\n",
    "param_save_minian = {\n",
    "    \"dpath\": minian_ds_path,\n",
    "    \"meta_dict\": dict(session=-1, animal=-2),\n",
    "    \"overwrite\": True,\n",
    "}\n",
    "\n",
    "# Pre-processing Parameters#\n",
    "param_load_videos = {\n",
    "#############     HERE     #############\n",
    "    \"pattern\": \"\\.avi$\",#r\"^(1[1-9])\\.avi$\",#\"1.avi\",#r\"^(0|[1-9]|1[0-5])\\.avi$\",#\"[0-9]+\\.avi$\",#\"blabla.avi\",#\"msCam[0-9]+\\.avi$\",\n",
    "########################################\n",
    "    \"dtype\": np.uint8,\n",
    "    \"downsample\": dict(frame=1, height=1, width=1),\n",
    "    \"downsample_strategy\": \"subset\",\n",
    "}\n",
    "param_denoise = {\"method\": \"median\", \"ksize\": parameters['ksize']}\n",
    "param_background_removal = {\"method\": \"tophat\", \"wnd\": parameters['wnd']}\n",
    "\n",
    "# Motion Correction Parameters#\n",
    "subset_mc = None\n",
    "param_estimate_motion = {\"dim\": \"frame\"}\n",
    "\n",
    "# Initialization Parameters#\n",
    "param_seeds_init = {\n",
    "    \"wnd_size\": 1000,\n",
    "    \"method\": \"rolling\",\n",
    "    \"stp_size\": 500,\n",
    "    \"max_wnd\": 15,\n",
    "    \"diff_thres\": 3,\n",
    "}\n",
    "param_pnr_refine = {\"noise_freq\": parameters['noise_freq'], \"thres\": parameters['thres']}\n",
    "param_ks_refine = {\"sig\": 0.05}\n",
    "param_seeds_merge = {\"thres_dist\": parameters['thres_dist'], \"thres_corr\": 0.8, \"noise_freq\": 0.06}\n",
    "param_initialize = {\"thres_corr\": 0.8, \"wnd\": 10, \"noise_freq\": 0.06}\n",
    "param_init_merge = {\"thres_corr\": 0.8}\n",
    "\n",
    "# CNMF Parameters#\n",
    "param_get_noise = {\"noise_range\": (0.06, 0.5)}\n",
    "param_first_spatial = {\n",
    "    \"dl_wnd\": 10,\n",
    "    \"sparse_penal\": parameters['spatial_sparse_penal1'],\n",
    "    \"size_thres\": (25, None),\n",
    "}\n",
    "param_first_temporal = {\n",
    "    \"noise_freq\": 0.06,\n",
    "    \"sparse_penal\": parameters['temp_sparse_penal1'],\n",
    "    \"p\": 1,\n",
    "    \"add_lag\": 20,\n",
    "    \"jac_thres\": 0.2,\n",
    "}\n",
    "param_first_merge = {\"thres_corr\": 0.8}\n",
    "param_second_spatial = {\n",
    "    \"dl_wnd\": 10,\n",
    "    \"sparse_penal\": parameters['spatial_sparse_penal2'],\n",
    "    \"size_thres\": (25, None),\n",
    "}\n",
    "param_second_temporal = {\n",
    "    \"noise_freq\": 0.06,\n",
    "    \"sparse_penal\": parameters['temp_sparse_penal2'],\n",
    "    \"p\": 1,\n",
    "    \"add_lag\": 20,\n",
    "    \"jac_thres\": 0.4,\n",
    "}\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MINIAN_INTERMEDIATE\"] = intpath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import minian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "sys.path.append(minian_path)\n",
    "from minian.cnmf import (\n",
    "    compute_AtC,\n",
    "    compute_trace,\n",
    "    get_noise_fft,\n",
    "    smooth_sig,\n",
    "    unit_merge,\n",
    "    update_spatial,\n",
    "    update_temporal,\n",
    "    update_background,\n",
    ")\n",
    "from minian.initialization import (\n",
    "    gmm_refine,\n",
    "    initA,\n",
    "    initC,\n",
    "    intensity_refine,\n",
    "    ks_refine,\n",
    "    pnr_refine,\n",
    "    seeds_init,\n",
    "    seeds_merge,\n",
    ")\n",
    "from minian.motion_correction import apply_transform, estimate_motion\n",
    "from minian.preprocessing import denoise, remove_background\n",
    "from minian.utilities import (\n",
    "    TaskAnnotation,\n",
    "    get_optimal_chk,\n",
    "    load_videos,\n",
    "    open_minian,\n",
    "    save_minian,\n",
    ")\n",
    "from minian.visualization import (\n",
    "    CNMFViewer,\n",
    "    VArrayViewer,\n",
    "    generate_videos,\n",
    "    visualize_gmm_fit,\n",
    "    visualize_motion,\n",
    "    visualize_preprocess,\n",
    "    visualize_seeds,\n",
    "    visualize_spatial_update,\n",
    "    visualize_temporal_update,\n",
    "    write_video,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## module initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "dpath = os.path.abspath(dpath)\n",
    "hv.notebook_extension(\"bokeh\", width=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## start cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCluster(\n",
    "#cluster = LocalCUDACluster(\n",
    "    n_workers=4*n_workers,\n",
    "    memory_limit=\"4GB\",\n",
    "    resources={\"MEM\": 1},\n",
    "    threads_per_worker=2,\n",
    "    dashboard_address=\":8787\",\n",
    ")\n",
    "annt_plugin = TaskAnnotation()\n",
    "cluster.scheduler.add_plugin(annt_plugin)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler_info = client.scheduler_info()\n",
    "for worker, info in scheduler_info['workers'].items():\n",
    "    print(f\"Worker {worker}: {info['resources']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading videos and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "tutorial"
    ]
   },
   "outputs": [],
   "source": [
    "print(colored(\"______ LOADING VIDEOS ... ______\", \"light_yellow\"), file = open(\"CON\", \"w\") )\n",
    "param_load_videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "tutorial"
    ]
   },
   "source": [
    "If you wish to downsample the video, pass in a dictionary to `downsample`, with the name of dimensions as keys and  the downsampling folds as integer value.\n",
    "For example, `downsample=dict(\"frame\"=2)` will temporally downsample the video with a factor of 2.\n",
    "`downsample_strategy` will assume two values: either `\"subset\"`, meaning downsampling are carried out simply by subsetting the data, or `\"mean\"`, meaning a mean will be calculated on the window of downsampling (the latter being slower)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y_fm_chk.max(dim=\"frame\")\n",
    "varr = load_videos(dpath, **param_load_videos)\n",
    "varr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "varr = load_videos(dpath, **param_load_videos)\n",
    "chk, _ = get_optimal_chk(varr,csize = 512,  dtype=float)\n",
    "chk['frame'] = 50\n",
    "vlist = [dpath + os.sep + v for v in os.listdir(dpath) if re.search(param_load_videos['pattern'], v)]\n",
    "print(colored(\"loading {} videos \".format(len(vlist)), 'red'), file = open(\"CON\", \"w\") )\n",
    "print(colored(\"______ VIDEOS LOADED ______\", \"yellow\"), file = open(\"CON\", \"w\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varr = save_minian(\n",
    "    varr.chunk({\"frame\": chk[\"frame\"], \"height\": -1, \"width\": -1}).rename(\"varr\"),\n",
    "    intpath,\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## glow removal and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hv.output(size=output_size)\n",
    "if interactive:\n",
    "    vaviewer = VArrayViewer(varr, framerate=20, summary=[\"mean\", \"max\"])\n",
    "    display(vaviewer.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "fig, axes = plt.subplots(4, 4, figsize=(12, 12), constrained_layout=True)\n",
    "cmap = 'viridis'\n",
    "vmin, vmax = varr.min().compute(), varr.max().compute() # Set global color limits based on the data\n",
    "\n",
    "contrasts = []\n",
    "\n",
    "# Plot each frame in a 4x4 grid\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    im = ax.imshow(varr.sel(frame = i), cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "    ax.set_title(f\"Frame {i+1}\")\n",
    "    ax.axis('off')  # Hide empty subplots\n",
    "    #contrasts.append(np.max(varr.sel(frame = i).values) -np.min(varr.sel(frame = i).values))\n",
    "\n",
    "\n",
    "plt.suptitle(\"4x4 Heatmaps with Shared Colorbar\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varr_ref = varr.sel(subset) \n",
    "varr_min = varr_ref.sel(frame=slice(5, len(varr.frame)-1)).min(\"frame\").compute()\n",
    "varr_ref = varr_ref - varr_min\n",
    "\n",
    "print(colored(\"______ PREPROCESSING ... ______\", \"light_yellow\"), file = open(\"CON\", \"w\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "# plotting background\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(varr_min, cmap='hot', aspect='auto') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "\n",
    "hv.output(size=int(output_size * 0.7))\n",
    "if interactive:\n",
    "    vaviewer = VArrayViewer(\n",
    "        [varr.rename(\"original\").sel(frame=slice(1000, len(varr.frame)-1)), varr_ref.rename(\"glow_removed\").sel(frame=slice(1000, len(varr.frame)-1))],\n",
    "        framerate=20,\n",
    "        summary=None,\n",
    "        layout=True,\n",
    "    )\n",
    "    display(vaviewer.show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'> STOP 2</font> <font color='red'> denoise</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "tutorial"
    ]
   },
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "param_denoise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "tutorial"
    ]
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Generally `ksize=5` is good (approximately half the diamater of the largest cell).\n",
    "Note that if you do want to play with the ksize, it has to be odd number.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "hv.output(size=int(output_size * 0.6))\n",
    "if interactive:\n",
    "    display(\n",
    "        visualize_preprocess(\n",
    "            varr_ref.isel(frame=2000).compute(),\n",
    "            denoise,\n",
    "            method=[\"median\"],\n",
    "            ksize=[5, 7, 9,11,13],\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "<font color='red'> Don't forget to update the parameter ksize</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   <font color='red'> ____________________________________________________________</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "param_denoise[\"ksize\"] = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(colored(\"ksize :\", \"light_magenta\"),  file = open(\"CON\", \"w\") )\n",
    "print(colored(param_denoise[\"ksize\"], \"light_magenta\"),  file = open(\"CON\", \"w\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   <font color='red'> ____________________________________________________________</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varr_ref = denoise(varr_ref, **param_denoise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'> STOP 3 </font> <font color='red'>background removal </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "tutorial"
    ]
   },
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "param_background_removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "tutorial"
    ]
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Pragmatically `wnd=15` works well.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "hv.output(size=int(output_size * 0.6))\n",
    "if interactive:\n",
    "    display(\n",
    "        visualize_preprocess(\n",
    "            varr_ref.isel(frame=3000).compute(),\n",
    "            remove_background,\n",
    "            method=[\"tophat\"],\n",
    "            wnd=[10, 15, 20],\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "<font color='red'>Don't forget to update the parameter wnd</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   <font color='red'> ____________________________________________________________</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "wnd = 15\n",
    "param_background_removal[\"wnd\"] = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(colored(\"wnd :\", \"light_magenta\"), file = open(\"CON\", \"w\")  )\n",
    "print(colored(param_background_removal[\"wnd\"], \"light_magenta\"), file = open(\"CON\", \"w\")  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   <font color='red'> ____________________________________________________________</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varr_ref = remove_background(varr_ref, **param_background_removal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "tutorial"
    ]
   },
   "source": [
    "Here we are saving our pre-processed video (`varr_ref`) into the intermediate folder (`intpath`).\n",
    "Note that for every saved variable a separate folder will be created based on the `.name` attribute of that variable.\n",
    "And variables with the same `.name` attribute will be saved to same folder regardless the variable name, potentially overwritting each other!\n",
    "Here we [rename](http://xarray.pydata.org/en/stable/generated/xarray.DataArray.rename.html) it to `\"varr_ref\"` so that the saved folder will be named \"varr_ref.zarr\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varr_ref = save_minian(varr_ref.rename(\"varr_ref\"), dpath=intpath, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motion Correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## estimate motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "tutorial"
    ]
   },
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "param_estimate_motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motion = estimate_motion(varr_ref.sel(subset_mc), **param_estimate_motion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "tutorial"
    ]
   },
   "outputs": [],
   "source": [
    "param_save_minian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "tutorial"
    ]
   },
   "source": [
    "As mentioned before `param_save_minian` decides how your data will be saved and what metadata will be stored.\n",
    "Additionally we use the `chk` variable earlier to make sure all our data have same chunk size along same dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motion = save_minian(\n",
    "    motion.rename(\"motion\").chunk({\"frame\": chk[\"frame\"]}), **param_save_minian\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## apply transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y = apply_transform(varr_ref, motion, fill=0)\n",
    "print(colored(\"______ PREPROCESSING DONE ______\", \"yellow\"), file = open(\"CON\", \"w\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.shape, Y.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "tutorial"
    ]
   },
   "source": [
    "Here we save two versions of the motion-corrected movie `Y`.\n",
    "Their contents are identical.\n",
    "The only difference is how they are chunked.\n",
    "Also note that we convert the data to `float` type for better downstream processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Y_fm_chk = save_minian(Y.astype(float).rename(\"Y_fm_chk\"), intpath, overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load for debugging \n",
    "varr_ref = xr.open_zarr('./minian_intermediate/varr_ref.zarr')\n",
    "varr = xr.open_zarr('./minian_intermediate/varr.zarr')\n",
    "Y_fm_chk = xr.open_zarr('./minian_intermediate/Y_fm_chk.zarr') \n",
    "# Y_hw_chk = xr.open_zarr('./minian_intermediate/Y_hw_chk.zarr')\n",
    "# varr_ref = xr.open_zarr('./varr_ref_pipeline.zarr')\n",
    "# varr = xr.open_zarr('./varr_pipeline.zarr')\n",
    "# Y_fm_chk = xr.open_zarr('./Y_fm_chk_pipeline.zarr') \n",
    "# Y_hw_chk = xr.open_zarr('./Y_hw_chk_pipeline.zarr')\n",
    "\n",
    "Y_fm_chk = Y_fm_chk.to_array().squeeze(axis=0)\n",
    "# Y_hw_chk = Y_hw_chk.to_array().squeeze(axis=0)\n",
    "varr = varr.to_array().squeeze(axis=0)\n",
    "varr_ref = varr_ref.to_array().squeeze(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate video for motion-correction"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vid_arr = xr.concat([varr_ref, Y_fm_chk], \"width\").chunk({\"width\": -1})\n",
    "write_video(vid_arr, \"minian_mc.mp4\",param_save_minian['dpath']) #dpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(colored(\"______ RESULTS SAVED ______\", \"light_green\"), file = open(\"CON\", \"w\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute max projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(colored(\"______ IDENTIFYING CELLS ______\", \"light_yellow\"), file = open(\"CON\", \"w\") )\n",
    "max_proj = save_minian(\n",
    "    Y_fm_chk.max(dim=\"frame\").rename(\"max_proj\"), **param_save_minian\n",
    ").compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#threshold = (Y_fm_chk.mean() + 100 * Y_fm_chk.std()).values\n",
    "threshold = 80.0\n",
    "print(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Replace values above threshold with NaN\n",
    "masked_array = xr.where(Y_fm_chk <= threshold, Y_fm_chk, np.nan)\n",
    "# 2) Find the maximum across (width, height) of only the values that survived the mask\n",
    "#    We often do .compute() here so we have a small in-memory array\n",
    "frame_max = masked_array.min(dim=(\"width\", \"height\"), skipna=True).compute()\n",
    "# 3) Wherever original array is NaN, fill with the broadcasted max\n",
    "#    xarray will handle broadcasting of \"frame_max\" automatically\n",
    "Y_fm_chk = xr.where(masked_array.notnull(), masked_array, frame_max)\n",
    "# 4) Persist if desired\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "write_video( varr, \"processedvid.mp4\",param_save_minian['dpath'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generating over-complete set of seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "tutorial"
    ]
   },
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "print(param_seeds_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_seeds_init['wnd_size'] = 7000#20000\n",
    "param_seeds_init['stp_size'] = 3000#15000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = seeds_init(Y_fm_chk, **param_seeds_init)\n",
    "seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hw_chk = save_minian(\n",
    "    Y_fm_chk.rename(\"Y_hw_chk\"),\n",
    "    intpath,\n",
    "    overwrite=True,\n",
    "    chunks={\"frame\": -1, \"height\": chk[\"height\"], \"width\": chk[\"width\"]},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_proj = Y_fm_chk.max(\"frame\").rename(\"max_proj\").compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(max_proj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "tutorial"
    ]
   },
   "source": [
    "The `seeds` variable is a [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html), with each row representing a seed.\n",
    "The column \"height\" and \"width\" defines the location of the seed.\n",
    "The column \"seeds\" is the number of chunks where the particular seed/pixel is considered a local maxima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter seeds on video artefact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(0, len(varr.height)-1, 1)\n",
    "counts, bin_edges = np.histogram(seeds.height.values, bins)\n",
    "import pandas as pd\n",
    "s = pd.Series(counts)\n",
    "\n",
    "window_size = 10\n",
    "rolling_mean = s.rolling(window_size, center = True).mean().fillna(0)\n",
    "\n",
    "threshold_height = 3*np.std(counts)+rolling_mean\n",
    "#plt.plot(counts)\n",
    "#plt.plot(threshold_height, color = 'r')\n",
    "\n",
    "height_out = np.where(counts > threshold_height)\n",
    "print(height_out)\n",
    "#plt.xlim([230, 240])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bins = np.arange(0, len(varr.width)-1, 1)\n",
    "counts, bin_edges = np.histogram(seeds.width.values, bins)\n",
    "s = pd.Series(counts)\n",
    "window_size = 10\n",
    "rolling_mean = s.rolling(window_size, center = True).mean().fillna(0)\n",
    "\n",
    "threshold_width = 3*np.std(counts)+rolling_mean\n",
    "#plt.plot(counts)\n",
    "#plt.plot(3*np.std(counts)+rolling_mean, color = 'r')\n",
    "\n",
    "width_out = np.where(counts > threshold_width)\n",
    "print(width_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds['is_artefact'] = False\n",
    "seeds['is_artefact'] = seeds['width'].isin(np.concatenate((width_out[0] ,width_out[0]+1,width_out[0]-1))) | seeds['height'].isin(np.concatenate((height_out[0] ,height_out[0]+1,height_out[0]-1)))\n",
    "\n",
    "## IMPORTANT ##\n",
    "seeds = seeds[seeds['is_artefact'] == False]\n",
    "(seeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### back to the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.output(size=output_size)\n",
    "visualize_seeds(max_proj, seeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'> STOP 4 </font> <font color='red'>peak-noise-ratio refine</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "\n",
    "#%%time\n",
    "if interactive:\n",
    "    noise_freq_list = [0.005, 0.01, 0.02, 0.06, 0.1, 0.2, 0.3, 0.45, 0.6, 0.8]\n",
    "    example_seeds = seeds.sample(6, axis=\"rows\")\n",
    "    example_trace = Y_hw_chk.sel(\n",
    "        height=example_seeds[\"height\"].to_xarray(),\n",
    "        width=example_seeds[\"width\"].to_xarray(),\n",
    "    ).rename(**{\"index\": \"seed\"})\n",
    "    smooth_dict = dict()\n",
    "    for freq in noise_freq_list:\n",
    "        trace_smth_low = smooth_sig(example_trace, freq)\n",
    "        trace_smth_high = smooth_sig(example_trace, freq, btype=\"high\")\n",
    "        trace_smth_low = trace_smth_low.compute()\n",
    "        trace_smth_high = trace_smth_high.compute()\n",
    "        hv_trace = hv.HoloMap(\n",
    "            {\n",
    "                \"signal\": (\n",
    "                    hv.Dataset(trace_smth_low)\n",
    "                    .to(hv.Curve, kdims=[\"frame\"])\n",
    "                    .opts(frame_width=300, aspect=2, ylabel=\"Signal (A.U.)\")\n",
    "                ),\n",
    "                \"noise\": (\n",
    "                    hv.Dataset(trace_smth_high)\n",
    "                    .to(hv.Curve, kdims=[\"frame\"])\n",
    "                    .opts(frame_width=300, aspect=2, ylabel=\"Signal (A.U.)\")\n",
    "                ),\n",
    "            },\n",
    "            kdims=\"trace\",\n",
    "        ).collate()\n",
    "        smooth_dict[freq] = hv_trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "tutorial"
    ]
   },
   "source": [
    "\n",
    "At the end of the process, we put together a `smooth_dict`.\n",
    "Here we convert that into an interactive plot, from which we can determine the frequency that best separates noise and signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "\n",
    "hv.output(size=int(output_size * 0.7))\n",
    "if interactive:\n",
    "    hv_res = (\n",
    "        hv.HoloMap(smooth_dict, kdims=[\"noise_freq\"])\n",
    "        .collate()\n",
    "        .opts(aspect=2)\n",
    "        .overlay(\"trace\")\n",
    "        .layout(\"seed\")\n",
    "        .cols(3)\n",
    "    )\n",
    "    display(hv_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "tutorial"
    ]
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>picking noise frequency</strong>\n",
    "\n",
    "We can now use the interactive visualization to pick the best cut-off frequency.\n",
    "Here is an example of what you might see:\n",
    "\n",
    "<div stype=\"clear:both\"><img src=\"img/param_pnr.png\" style=\"width: 50%\"/></div>\n",
    "\n",
    "We are looking for the frequency that can best seperate real signal from noise.\n",
    "Hence, `noise_freq=0.005` in the example is not ideal, since real calcium activities are overly smoothed as well.\n",
    "At the same time, `noise_freq=0.45` is not ideal either, since a lot of high-frequency noise are visible in the signal.\n",
    "Hence, `noise_freq=0.05` in the middle is a good choice in this example.\n",
    "Now, say you already found your parameters, it's time now to pass them in! Either go back to initial parameters setting step and modify them there, or call the parameter here and change its value/s accordingly.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "tutorial"
    ]
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "<font color='red'>Don't forget to update the parameters</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   <font color='red'> ____________________________________________________________</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "tutorial"
    ]
   },
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "\n",
    "noise_freq = 0.1\n",
    "param_pnr_refine[\"noise_freq\"] =noise_freq\n",
    "param_pnr_refine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(colored(\"noise_freq :\", \"light_magenta\"),  file = open(\"CON\", \"w\") )\n",
    "print(colored(param_pnr_refine[\"noise_freq\"], \"light_magenta\"),  file = open(\"CON\", \"w\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   <font color='red'> ____________________________________________________________</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'> STOP 5 </font> <font color='red'>seed threshold</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "seeds, pnr, gmm = pnr_refine(Y_hw_chk, seeds, **param_pnr_refine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "tutorial"
    ]
   },
   "source": [
    "First we filter the temporal activities for each seed using the `noise_freq` we choose.\n",
    "**signal** is defined as the low-pass filtered temporal signal, while **noise** is high-pass filtered signal.\n",
    "Then we compute the peak-to-peak value (max minus min) for both the **real** signal and **noise** signal.\n",
    "The peak-noise-ratio is defined as the ratio between the peak-to-peak value of **signal** and that of **noise**.\n",
    "We then threshold the seeds based on this peak-noise-ratio, with the assumption that temporal activities from real cells should have higher fluctuation in the low-frequency range and lower fluctuation in the high-frequency range.\n",
    "`thres` is the threshold for peak-noise-ratios.\n",
    "Pragmatically `thres=1` works fine and makes sense.\n",
    "You can also use `thres=\"auto\"`, where a gaussian mixture model with 2 components will be run on the peak-noise-ratios and seeds will be selected if they belong to the \"higher\" gaussian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "tutorial"
    ]
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "If you see seeds being filtered out that you believe should be cells, either skip this step or try lower the threshold a bit.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.output(size=output_size)\n",
    "visualize_seeds(max_proj, seeds[seeds['is_artefact'] == False], \"mask_pnr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "<font color='red'>Don't forget to update the parameters</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   <font color='red'> ____________________________________________________________</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "thres = 0.5\n",
    "param_pnr_refine[\"thres\"] =thres\n",
    "param_pnr_refine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(colored(\"thres :\", \"light_magenta\"),  file = open(\"CON\", \"w\") )\n",
    "print(colored(param_pnr_refine[\"thres\"], \"light_magenta\"),  file = open(\"CON\", \"w\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   <font color='red'> ____________________________________________________________</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ks refine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "tutorial"
    ]
   },
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "param_ks_refine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "seeds = ks_refine(Y_hw_chk, seeds, **param_ks_refine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hv.output(size=output_size)\n",
    "visualize_seeds(max_proj, seeds, \"mask_ks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'> STOP 6 </font> <font color='red'>merge seeds</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "seeds_final = seeds[seeds[\"mask_ks\"] & seeds[\"mask_pnr\"] & ~seeds[\"is_artefact\"]].reset_index(drop=True)\n",
    "# seeds_final = seeds[seeds[\"mask_ks\"] & seeds[\"mask_pnr\"]].reset_index(drop=True)\n",
    "\n",
    "# seeds_final[0:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds_final = seeds_merge(Y_hw_chk, max_proj, seeds_final, **param_seeds_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "tutorial"
    ]
   },
   "source": [
    "We visualize the result on top of the max projection.\n",
    "The red dots here indicate seeds that has been merged to nearby seeds (those shown in white)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hv.output(size=output_size)\n",
    "visualize_seeds(max_proj, seeds_final, \"mask_mrg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "<font color='red'>Don't forget to update the parameter thres_dist</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   <font color='red'> ____________________________________________________________</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "tutorial"
    ]
   },
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "param_seeds_merge['thres_dist'] = 6\n",
    "param_seeds_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(colored(\"thres_dist :\", \"light_magenta\"),  file = open(\"CON\", \"w\") )\n",
    "print(colored(param_seeds_merge['thres_dist'], \"light_magenta\"),  file = open(\"CON\", \"w\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   <font color='red'> ____________________________________________________________</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(colored(\"______ CELLS FOUND ______\", \"yellow\"), file = open(\"CON\", \"w\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize spatial matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "tutorial"
    ]
   },
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "\n",
    "param_initialize['wnd'] = wnd\n",
    "param_initialize['noise_freq'] = noise_freq\n",
    "param_initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "print(colored(\"______ COMPUTING TRACES ______\", \"light_yellow\"), file = open(\"CON\", \"w\") )\n",
    "A_init = initA(Y_hw_chk, seeds_final[seeds_final[\"mask_mrg\"]], **param_initialize)\n",
    "A_init = save_minian(A_init.rename(\"A_init\"), intpath, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize temporal matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "C_init = initC(Y_fm_chk, A_init)\n",
    "C_init = save_minian(\n",
    "    C_init.rename(\"C_init\"), intpath, overwrite=True, chunks={\"unit_id\": 1, \"frame\": -1}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "tutorial"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "%%skip_cell\n",
    "param_init_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "A, C = unit_merge(A_init, C_init, **param_init_merge)\n",
    "A = save_minian(A.rename(\"A\"), intpath, overwrite=True)\n",
    "C = save_minian(C.rename(\"C\"), intpath, overwrite=True)\n",
    "C_chk = save_minian(\n",
    "    C.rename(\"C_chk\"),\n",
    "    intpath,\n",
    "    overwrite=True,\n",
    "    chunks={\"unit_id\": -1, \"frame\": chk[\"frame\"]},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize background terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "tutorial"
    ]
   },
   "source": [
    "Finally, we need two more terms: `b` and `f`, representing the spatial footprint and temporal dynamics of the background, respectively.\n",
    "We first compute an estimation of cellular activities by taking the outer product of `A` and `C`, resulting in an video array with dimesion `height`, `width` and `frame`.\n",
    "We then subtract this array from `Y_fm_chk`, resulting in a \"residule\" movie.\n",
    "Then `b` is estimated as the mean projection of the \"residule\" movie, while `f` is estimated as the fluorescence fluctuation of `b` that best fit the \"residule\" movie (least-square solution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "b, f = update_background(Y_fm_chk, A, C_chk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Y_fm_chk[500])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "max_frame = Y_fm_chk.max(dim=\"frame\").compute()\n",
    "print(f'max frame pixel: {max_frame.max().values}')\n",
    "plt.imshow(max_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f = save_minian(f.rename(\"f\"), intpath, overwrite=True)\n",
    "b = save_minian(b.rename(\"b\"), intpath, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualization of initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "tutorial"
    ]
   },
   "source": [
    "Finally we visualize the result of our initialization by plotting a projection of the spatial matrix `A`, a raster of the temporal matrix `C`, as well as background terms `b` and `f`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "\n",
    "hv.output(size=int(output_size * 0.55))\n",
    "im_opts = dict(\n",
    "    frame_width=500,\n",
    "    aspect=A.sizes[\"width\"] / A.sizes[\"height\"],\n",
    "    cmap=\"Viridis\",\n",
    "    colorbar=True,\n",
    ")\n",
    "cr_opts = dict(frame_width=750, aspect=1.5 * A.sizes[\"width\"] / A.sizes[\"height\"])\n",
    "(\n",
    "    regrid(\n",
    "        hv.Image(\n",
    "            A.max(\"unit_id\").rename(\"A\").compute().astype(np.float32),\n",
    "            kdims=[\"width\", \"height\"],\n",
    "        ).opts(**im_opts)\n",
    "    ).relabel(\"Initial Spatial Footprints\")\n",
    "    + regrid(\n",
    "        hv.Image(\n",
    "            C.rename(\"C\").compute().astype(np.float32), kdims=[\"frame\", \"unit_id\"]\n",
    "        ).opts(cmap=\"viridis\", colorbar=True, **cr_opts)\n",
    "    ).relabel(\"Initial Temporal Components\")\n",
    "    + regrid(\n",
    "        hv.Image(\n",
    "            b.rename(\"b\").compute().astype(np.float32), kdims=[\"width\", \"height\"]\n",
    "        ).opts(**im_opts)\n",
    "    ).relabel(\"Initial Background Sptial\")\n",
    "    + datashade(hv.Curve(f.rename(\"f\").compute(), kdims=[\"frame\"]), min_alpha=200)\n",
    "    .opts(**cr_opts)\n",
    "    .relabel(\"Initial Background Temporal\")\n",
    ").cols(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "tutorial"
    ]
   },
   "source": [
    "This section assumes you already have some background knowledge about the CNMF algorithm.\n",
    "Please refer to the [the paper](https://www.sciencedirect.com/science/article/pii/S0896627315010843) for detailed information of the algorithm. \n",
    "\n",
    "As a quick recap, here is the essential idea of CNMF:\n",
    "We believe our movie, `Y`, with dimensions `height`, `width` and `frame`, can be written in (and thus broken down as) the following equation:\n",
    "\n",
    "$$\\mathbf{Y} = \\mathbf{A}^T \\mathbf{C} + \\mathbf{b}^T \\mathbf{f} + \\epsilon$$\n",
    "\n",
    "where:\n",
    "\n",
    "* `A` is the spatial footprint of each unit, with dimension `height`, `width` and `unit_id`.\n",
    "* `C` is the temporal activities of each unit, with dimension `unit_id` and `frame`.\n",
    "* `b` and `f` are the spatial footprint and temporal activities of some background, respectively.\n",
    "* $\\epsilon$ is the noise.\n",
    "\n",
    "Note that strictly speaking, matrix multiplication is usually only defined for two dimensional matrices, but our `A` here has three dimensions, so in fact we are taking the [tensor product](https://en.wikipedia.org/wiki/Tensor_product) of `A` and `C`, reducing the dimension `unit_id`.\n",
    "This might seem to complicate things (compared to just treating `height` and `width` as one flattened `spatial` dimension), but it ends up making some sense.\n",
    "When you take a dot product of any two \"matrices\" on a certain **dimension**, all that is happening is a **product** followed by a **sum** -- you take the product for all pairs of numbers with the the same indexes from the two \"matrices\", and then you take the sum of all those products along the dimension.\n",
    "Thus when we take the tensor product of `A` and `C`, we are actually multiplying all those numbers in dimension `height`, `width` and `frame`, matched by `unit_id`, and then take the sum.\n",
    "Conceptually, for each unit, we are weighting the spatial footprint (`height` and `width`) by the fluorecense of that unit on given `frame`, which is the **product**, and then we are collapsing all units together, which is the **sum**.\n",
    "With that, the equation above is trying to say that our movie is made up of a weighted sum of the spatial footprint and temporal activities of all units, plus some background and noise.\n",
    "\n",
    "Now, there is another rule about `C` that separates it from background and noise:\n",
    "Each \"row\" of `C`, which is the temporal trace for each unit, should be described as an [autoregressive process](https://en.wikipedia.org/wiki/Autoregressive_model) (AR process), with a parameter `p` defining the **order** of the AR process:\n",
    "\n",
    "$$ c(t) = \\sum_{i=0}^{p}\\gamma_i c(t-i) + s(t) + \\epsilon$$\n",
    "\n",
    "where:\n",
    "\n",
    "* $c(t)$ is the calcium concentration at time (`frame`) $t$.\n",
    "* $s(t)$ is spike/firing rate at time $t$.\n",
    "* $\\epsilon$ is noise.\n",
    "\n",
    "Basically, this equation is trying to say that at any given time $t$, the calcium concentration at that moment $c(t)$ depends on the spike at that moment $s(t)$, as well as its own history up to `p` time-steps back $c(t-i)$, scaled by some parameters $\\gamma_i$s, plus some noise $\\epsilon$.\n",
    "Another intuition of this equation comes from looking at different `p`s: when `p=0`, the calcium concentration is an exact copy of the spiking activities, which is probably not true.\n",
    "When `p=1`, the calcium concentration has an instant rise in response to a spike followed by an exponential decay.\n",
    "When `p=2`, calcium concentration has some rise time following a spike and an exponential decay.\n",
    "\n",
    "With all this in mind, CNMF tries to find the spatial matrix (`A`) and temporal activity (`C`) (along with `b` and `f`) that best describe `Y`.\n",
    "There are a few more important practical concerns: Firstly we cannot solve this problem in one shot -- we need to iteratively and separately update `A` and `C` to approach the true solution.\n",
    "Often enough,  two iterations  after the initialization seem to give good enough results, but you can always add more iterations.\n",
    "Secondly, by intuition you may define \"best describe `Y`\" as the results that minimize the noise/error $\\epsilon$.\n",
    "However we have to control for the [sparsity](https://en.wikipedia.org/wiki/Sparse_matrix) of our model as well, since we do not want every little random pixel that happens to correlate with a cell to be counted as part of the spatial footprint of the cell (non-sparse `A`), nor do we want a tiny spike at every frame trying to explain every noisy peak we observe (non-sparse `C`).\n",
    "Thus, the balance between fidelity (minimizing error) and sparsity (minimizing non-zero entries) is an important concern for both the spatial and temporal update."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## estimate spatial noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "tutorial"
    ]
   },
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "param_get_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "tutorial"
    ]
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "It is recommended to use the cut-off frequency you find during [peak-noise-ratio refine](#peak-noise-ratio-refine) as the lower bound of `noise_range` to be consistent.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "sn_spatial = get_noise_fft(Y_hw_chk, **param_get_noise)\n",
    "sn_spatial = save_minian(sn_spatial.rename(\"sn_spatial\"), intpath, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'> STOP 7 </font> <font color='red'>first spatial update</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parameter exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "if interactive:\n",
    "    units = np.random.choice(A.coords[\"unit_id\"], 10, replace=False)\n",
    "    units.sort()\n",
    "    A_sub = A.sel(unit_id=units).persist()\n",
    "    C_sub = C.sel(unit_id=units).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "#%%time\n",
    "if interactive:\n",
    "    sprs_ls = [0.005, 0.01, 0.05]\n",
    "    A_dict = dict()\n",
    "    C_dict = dict()\n",
    "    for cur_sprs in sprs_ls:\n",
    "        cur_A, cur_mask, cur_norm = update_spatial(\n",
    "            Y_hw_chk,\n",
    "            A_sub,\n",
    "            C_sub,\n",
    "            sn_spatial,\n",
    "            in_memory=True,\n",
    "            dl_wnd=param_first_spatial[\"dl_wnd\"],\n",
    "            sparse_penal=cur_sprs,\n",
    "        )\n",
    "        if cur_A.sizes[\"unit_id\"]:\n",
    "            A_dict[cur_sprs] = cur_A.compute()\n",
    "            C_dict[cur_sprs] = C_sub.sel(unit_id=cur_mask).compute()\n",
    "    hv_res = visualize_spatial_update(A_dict, C_dict, kdims=[\"sparse penalty\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "hv.output(size=int(output_size * 0.6))\n",
    "if interactive:\n",
    "    display(hv_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "tutorial"
    ]
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>choosing sparse penalty for spatial update</strong>\n",
    "\n",
    "Here is an example of what you might see during the parameter exploration:\n",
    "    \n",
    "<div stype=\"clear:both\"><img src=\"img/param_spatial_update.png\" style=\"width: 70%\"/></div>\n",
    "\n",
    "As you can see the `sparse_penal` parameter directly controls the overal sparsity of the resulting spatial footprints.\n",
    "When `sparse_penal=0.01`, the spatial footprints extend far away from the centorids of cells, resulting in high overlap between cells and unnatrual shapes.\n",
    "This is more evident from the binary spatial footprints.\n",
    "At the same time, when `sparse_penal=1`, the algorithm become too strict, and only one cell is left as acceptable.\n",
    "This is also not desirable and we usually want to avoid dropping cells during spatial update.\n",
    "Hence in this example, `sparse_penal=0.3` is considered a good choice among the three cases.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spatial update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "tutorial"
    ]
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "</font> <font color='red'>Don't forget to update the sparse penalty parameter</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   <font color='red'> ____________________________________________________________</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "tutorial"
    ]
   },
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "param_first_spatial['sparse_penal'] = 0.005\n",
    "param_first_spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(colored(\"sparse_penal :\", \"light_magenta\"),  file = open(\"CON\", \"w\") )\n",
    "print(colored(param_first_spatial['sparse_penal'], \"light_magenta\"),  file = open(\"CON\", \"w\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   <font color='red'> ____________________________________________________________</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "tutorial"
    ]
   },
   "source": [
    "When carrying out spatial update, it is very inefficient to estimate a weight for all the cells for each pixel.\n",
    "Instead, when updating for each pixel, we only want to consider cells that are close by and ignore cells that are very far from the pixel being updated.\n",
    "For this purpose we carry out a [morphological dilation](https://homepages.inf.ed.ac.uk/rbf/HIPR2/dilate.htm) on the spatial footprints of each cell using the previous estimation of `A`.\n",
    "We then binarize this dilated spatial footprints matrix and use it as a mask.\n",
    "Then when updating for each pixel, only cells that have non-zero values in the mask on this pixel will be considered for update.\n",
    "The parameter `dl_wnd` controls the window size of the morphological dilation operation.\n",
    "\n",
    "The scalar `sparse_penal` controls the balance between error objective and the l1-norm term.\n",
    "The higher the `sparse_penal`, the sparser the result will become.\n",
    "It is hard to estimate theoretically, and the best way to set this is through parameter exploration.\n",
    "\n",
    "Lastly, it is often convenient to filter out cells that has either too large or too small spatial footprints at this step.\n",
    "The `size_thres` controls the range of area (number of non-zero pixels) of the spatial footprints that will be accepted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "A_new, mask, norm_fac = update_spatial(\n",
    "    Y_hw_chk, A, C, sn_spatial, **param_first_spatial\n",
    ")\n",
    "C_new = save_minian(\n",
    "    (C.sel(unit_id=mask) * norm_fac).rename(\"C_new\"), intpath, overwrite=True\n",
    ")\n",
    "C_chk_new = save_minian(\n",
    "    (C_chk.sel(unit_id=mask) * norm_fac).rename(\"C_chk_new\"), intpath, overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After obtaining a better estimation of spatial footprints, we update the background terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "b_new, f_new = update_background(Y_fm_chk, A_new, C_chk_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualization of spatial footprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "hv.output(size=int(output_size * 0.6))\n",
    "opts = dict(\n",
    "    plot=dict(height=A.sizes[\"height\"], width=A.sizes[\"width\"], colorbar=True),\n",
    "    style=dict(cmap=\"Viridis\"),\n",
    ")\n",
    "(\n",
    "    regrid(\n",
    "        hv.Image(\n",
    "            A.max(\"unit_id\").compute().astype(np.float32).rename(\"A\"),\n",
    "            kdims=[\"width\", \"height\"],\n",
    "        ).opts(**opts)\n",
    "    ).relabel(\"Spatial Footprints Initial\")\n",
    "    + regrid(\n",
    "        hv.Image(\n",
    "            (A.fillna(0) > 0).sum(\"unit_id\").compute().astype(np.uint8).rename(\"A\"),\n",
    "            kdims=[\"width\", \"height\"],\n",
    "        ).opts(**opts)\n",
    "    ).relabel(\"Binary Spatial Footprints Initial\")\n",
    "    + regrid(\n",
    "        hv.Image(\n",
    "            A_new.max(\"unit_id\").compute().astype(np.float32).rename(\"A\"),\n",
    "            kdims=[\"width\", \"height\"],\n",
    "        ).opts(**opts)\n",
    "    ).relabel(\"Spatial Footprints First Update\")\n",
    "    + regrid(\n",
    "        hv.Image(\n",
    "            (A_new > 0).sum(\"unit_id\").compute().astype(np.uint8).rename(\"A\"),\n",
    "            kdims=[\"width\", \"height\"],\n",
    "        ).opts(**opts)\n",
    "    ).relabel(\"Binary Spatial Footprints First Update\")\n",
    ").cols(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "A = save_minian(\n",
    "    A_new.rename(\"A\"),\n",
    "    intpath,\n",
    "    overwrite=True,\n",
    "    chunks={\"unit_id\": 1, \"height\": -1, \"width\": -1},\n",
    ")\n",
    "b = save_minian(b_new.rename(\"b\"), intpath, overwrite=True)\n",
    "f = save_minian(\n",
    "    f_new.chunk({\"frame\": chk[\"frame\"]}).rename(\"f\"), intpath, overwrite=True\n",
    ")\n",
    "C = save_minian(C_new.rename(\"C\"), intpath, overwrite=True)\n",
    "C_chk = save_minian(C_chk_new.rename(\"C_chk\"), intpath, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'> STOP 8 </font> <font color='red'>first temporal update</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parameter exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "tutorial"
    ]
   },
   "source": [
    "First off we randomly select 10 cells to do parameter exploring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "if interactive:\n",
    "    units = np.random.choice(A.coords[\"unit_id\"], 10, replace=False)\n",
    "    units.sort()\n",
    "    A_sub = A.sel(unit_id=units).persist()\n",
    "    C_sub = C_chk.sel(unit_id=units).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "#%%time\n",
    "if interactive:\n",
    "    p_ls = [1]\n",
    "    sprs_ls = [0.1, 0.5, 1, 2]\n",
    "    add_ls = [20]\n",
    "    noise_ls = [0.06]\n",
    "    YA_dict, C_dict, S_dict, g_dict, sig_dict, A_dict = [dict() for _ in range(6)]\n",
    "    YrA = (\n",
    "        compute_trace(Y_fm_chk, A_sub, b, C_sub, f)\n",
    "        .persist()\n",
    "        .chunk({\"unit_id\": 1, \"frame\": -1})\n",
    "    )\n",
    "    for cur_p, cur_sprs, cur_add, cur_noise in itt.product(\n",
    "        p_ls, sprs_ls, add_ls, noise_ls\n",
    "    ):\n",
    "        ks = (cur_p, cur_sprs, cur_add, cur_noise)\n",
    "        print(\n",
    "            \"p:{}, sparse penalty:{}, additional lag:{}, noise frequency:{}\".format(\n",
    "                cur_p, cur_sprs, cur_add, cur_noise\n",
    "            )\n",
    "        )\n",
    "        cur_C, cur_S, cur_b0, cur_c0, cur_g, cur_mask = update_temporal(\n",
    "            A_sub,\n",
    "            C_sub,\n",
    "            YrA=YrA,\n",
    "            sparse_penal=cur_sprs,\n",
    "            p=cur_p,\n",
    "            use_smooth=True,\n",
    "            add_lag=cur_add,\n",
    "            noise_freq=cur_noise,\n",
    "        )\n",
    "        YA_dict[ks], C_dict[ks], S_dict[ks], g_dict[ks], sig_dict[ks], A_dict[ks] = (\n",
    "            YrA.compute(),\n",
    "            cur_C.compute(),\n",
    "            cur_S.compute(),\n",
    "            cur_g.compute(),\n",
    "            (cur_C + cur_b0 + cur_c0).compute(),\n",
    "            A_sub.compute(),\n",
    "        )\n",
    "    hv_res = visualize_temporal_update(\n",
    "        YA_dict,\n",
    "        C_dict,\n",
    "        S_dict,\n",
    "        g_dict,\n",
    "        sig_dict,\n",
    "        A_dict,\n",
    "        kdims=[\"p\", \"sparse penalty\", \"additional lag\", \"noise frequency\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "\n",
    "hv.output(size=int(output_size * 0.6))\n",
    "if interactive:\n",
    "    display(hv_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "tutorial"
    ]
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>choosing sparse penalty for temporal update</strong>\n",
    "\n",
    "Here is an example of what you might see during the parameter exploration:\n",
    "    \n",
    "<div stype=\"clear:both\"><img src=\"img/param_temporal_update.png\" style=\"width: 50%\"/></div>\n",
    "\n",
    "As you can see the `sparse_penal` parameter directly controls the overal sparsity of the resulting calcium dynamic and deconvolved spikes.\n",
    "When `sparse_penal=1`, the fitted spikes contains lots of small valued fluctuations, that mostly correspond to high-frequency noise instead of real calcium dynamic.\n",
    "At the same time, when `sparse_penal=10`, the sparse penalty is too large, and a lot of real calcium dynamics, as evident in the raw signal, are left out in the fitted calcium and spike traces.\n",
    "Hence in this example, `sparse_penal=3` is considered a good choice among the three cases.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "</font> <font color='red'>Don't forget to update the sparse penalty parameter</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   <font color='red'> ____________________________________________________________</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "param_first_temporal['sparse_penal'] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(colored(\"sparse_penal :\", \"light_magenta\"),  file = open(\"CON\", \"w\") )\n",
    "print(colored(param_first_temporal['sparse_penal'], \"light_magenta\"),  file = open(\"CON\", \"w\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   <font color='red'> ____________________________________________________________</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### temporal update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "YrA = save_minian(\n",
    "    compute_trace(Y_fm_chk, A, b, C_chk, f).rename(\"YrA\"),\n",
    "    intpath,\n",
    "    overwrite=True,\n",
    "    chunks={\"unit_id\": 1, \"frame\": -1},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "tutorial"
    ]
   },
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "param_first_temporal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "tutorial"
    ]
   },
   "source": [
    "Although we obtained `YrA` for each unit, it is still beneficial to group together units that heavily overlap, and carry out the update process group-wise instead of independently for each unit.\n",
    "This way the relative numerical relationship between heavily-overlapping units are better preserved.\n",
    "For this purpose, we compute pairwise [Jaccard index](https://en.wikipedia.org/wiki/Jaccard_index) for all units, which serve as a metric of overlap between spatial footprints of units.\n",
    "The parameter `jac_thres` is the threshold of Jaccard index above which units will be grouped together transitively.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Since the grouping of units is transitive and uses binarized spatial footprints, in practive you may find large amount of units being grouped together if the spatial footprints is not sparse enough.\n",
    "This lead to significantly increased memory demand, and potential \"masking\" effect between units (activities of highly active units suppress the activities of less active units when grouped together).\n",
    "If this happens, consider either refine the spatial footprints or increase the `jac_thres`.\n",
    "</div>\n",
    "\n",
    "Regarding the actual optimization process, the first thing we want to determine is order of the AR process `p`.\n",
    "Usually, `p=1` is good enough and tend to result in multiple spikes in the deconvolved signal `S` accounting for a single rise of calcium concentration in `C`.\n",
    "However, if you believe the rise time of your calcium signal is not neglectable, and a single rise of calcium concentration should be modeled as a single calcium event in the deconvolved signal `S`, then `p=2` is a better choice since it allows for modeling of non-zero rise time.\n",
    "\n",
    "Next, we estimate the AR coefficients from the auto-covariance of the `YrA` signal for each cell.\n",
    "Two additional steps can improve the reliability of this estimation.\n",
    "First, the `YrA` can be smoothed for estimation of the AR coefficients.\n",
    "This can help prevent the high frequency noise in `YrA` biasing the estimation of AR proces in to very fast dynamics.\n",
    "The `noise_freq` parameter is the cut-off frequency of this low-pass filtering.\n",
    "Secondly, although in theory only `p` auto-covariances are needed to solve `p` number of AR coefficients, we can use auto-covariance more than `p` time lags and solve for AR coefficients using least square.\n",
    "This help make the estimation numerically more stable.\n",
    "The `add_lag` parameter is the number of additional auto-covariance to use for estimating AR coefficients.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "The `noise_freq` should be set to those determined in [peak-noise-ratio refine](#peak-noise-ratio-refine) to be consistent.\n",
    "The `add_lag` usually have limited impact on the result as long as it is large enough.\n",
    "Pragmatically we have found `add_lag=20` works for most cases.\n",
    "However calcium dynamic are very slow in your data, you might have to increase `add_lag` so that auto-covariance with further time lag may contribute to the estimation of AR coefficients.\n",
    "</div>\n",
    "\n",
    "Finally, the scalar `sparse_penal` controls the balance between the error and l1-norm of `C` in the optimization objective.\n",
    "The higher the value, the sparser both `C` and `S` will become.\n",
    "It is hard to estimate theoretically, and the best way to set this is through parameter exploration.\n",
    "Note that despite the name, this is a completely different parameter than the one in spatial updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "C_new, S_new, b0_new, c0_new, g, mask = update_temporal(\n",
    "    A, C, YrA=YrA, **param_first_temporal\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualization of dropped units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "hv.output(size=int(output_size * 0.6))\n",
    "if interactive:\n",
    "    h, w = A.sizes[\"height\"], A.sizes[\"width\"]\n",
    "    im_opts = dict(aspect=w / h, frame_width=500, cmap=\"Viridis\")\n",
    "    cr_opts = dict(aspect=3, frame_width=1000)\n",
    "    bad_units = mask.where(mask == False, drop=True).coords[\"unit_id\"].values\n",
    "    if len(bad_units) > 0:\n",
    "        hv_res = (\n",
    "            hv.NdLayout(\n",
    "                {\n",
    "                    \"Spatial Footprint\": Dynamic(\n",
    "                        hv.Dataset(A.sel(unit_id=bad_units).compute().rename(\"A\"))\n",
    "                        .to(hv.Image, kdims=[\"width\", \"height\"])\n",
    "                        .opts(**im_opts)\n",
    "                    ),\n",
    "                    \"Spatial Footprints of Accepted Units\": Dynamic(\n",
    "                        hv.Image(\n",
    "                            A.sel(unit_id=mask).sum(\"unit_id\").compute().rename(\"A\"),\n",
    "                            kdims=[\"width\", \"height\"],\n",
    "                        ).opts(**im_opts)\n",
    "                    ),\n",
    "                }\n",
    "            )\n",
    "            + datashade(\n",
    "                hv.Dataset(YrA.sel(unit_id=bad_units).rename(\"raw\")).to(\n",
    "                    hv.Curve, kdims=[\"frame\"]\n",
    "                )\n",
    "            )\n",
    "            .opts(**cr_opts)\n",
    "            .relabel(\"Temporal Trace\")\n",
    "        ).cols(1)\n",
    "        display(hv_res)\n",
    "    else:\n",
    "        print(\"No rejected units to display\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualization of accepted units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "hv.output(size=int(output_size * 0.6))\n",
    "if interactive:\n",
    "    sig = C_new + b0_new + c0_new\n",
    "    display(\n",
    "        visualize_temporal_update(\n",
    "            YrA.sel(unit_id=mask),\n",
    "            C_new,\n",
    "            S_new,\n",
    "            g,\n",
    "            sig,\n",
    "            A.sel(unit_id=mask),\n",
    "        )\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "C = save_minian(\n",
    "    C_new.rename(\"C\").chunk({\"unit_id\": 1, \"frame\": -1}), intpath, overwrite=True\n",
    ")\n",
    "C_chk = save_minian(\n",
    "    C.rename(\"C_chk\"),\n",
    "    intpath,\n",
    "    overwrite=True,\n",
    "    chunks={\"unit_id\": -1, \"frame\": chk[\"frame\"]},\n",
    ")\n",
    "S = save_minian(\n",
    "    S_new.rename(\"S\").chunk({\"unit_id\": 1, \"frame\": -1}), intpath, overwrite=True\n",
    ")\n",
    "b0 = save_minian(\n",
    "    b0_new.rename(\"b0\").chunk({\"unit_id\": 1, \"frame\": -1}), intpath, overwrite=True\n",
    ")\n",
    "c0 = save_minian(\n",
    "    c0_new.rename(\"c0\").chunk({\"unit_id\": 1, \"frame\": -1}), intpath, overwrite=True\n",
    ")\n",
    "A = A.sel(unit_id=C.coords[\"unit_id\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "tutorial"
    ]
   },
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "param_first_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "tutorial"
    ]
   },
   "source": [
    "The idea is straight-forward and based purely on correlation of temporal activities.\n",
    "Any units whose spatial footprints share at least one pixel are considered potential targets for merging, and any of these units that have a correlation of temporal activities higher than `thres_corr` will be merged. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "A_mrg, C_mrg, [sig_mrg] = unit_merge(A, C, [C + b0 + c0], **param_first_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "hv.output(size=int(output_size * 0.6))\n",
    "opts_im = dict(frame_width=500, aspect=2, colorbar=True, cmap=\"Viridis\")\n",
    "(\n",
    "    regrid(\n",
    "        hv.Image(\n",
    "            C.compute().astype(np.float32).rename(\"c1\"), kdims=[\"frame\", \"unit_id\"]\n",
    "        )\n",
    "        .relabel(\"Temporal Signals Before Merge\")\n",
    "        .opts(**opts_im)\n",
    "    )\n",
    "    + regrid(\n",
    "        hv.Image(\n",
    "            C_mrg.compute().astype(np.float32).rename(\"c2\"), kdims=[\"frame\", \"unit_id\"]\n",
    "        )\n",
    "        .relabel(\"Temporal Signals After Merge\")\n",
    "        .opts(**opts_im)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "tutorial"
    ]
   },
   "source": [
    "Once we are satisfied with the result of merging we can commit to saving them to intermediate folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "A = save_minian(A_mrg.rename(\"A_mrg\"), intpath, overwrite=True)\n",
    "C = save_minian(C_mrg.rename(\"C_mrg\"), intpath, overwrite=True)\n",
    "C_chk = save_minian(\n",
    "    C.rename(\"C_mrg_chk\"),\n",
    "    intpath,\n",
    "    overwrite=True,\n",
    "    chunks={\"unit_id\": -1, \"frame\": chk[\"frame\"]},\n",
    ")\n",
    "sig = save_minian(sig_mrg.rename(\"sig_mrg\"), intpath, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'> STOP 9</font> <font color='red'>second spatial update</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "tutorial"
    ]
   },
   "source": [
    "This section analogous to the [first time](#first-spatial-update) we so spatial update except for changes in variable names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parameter exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "if interactive:\n",
    "    units = np.random.choice(A.coords[\"unit_id\"], 10, replace=False)\n",
    "    units.sort()\n",
    "    A_sub = A.sel(unit_id=units).persist()\n",
    "    C_sub = sig.sel(unit_id=units).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "#%%time\n",
    "if interactive:\n",
    "    sprs_ls = [5e-3, 1e-2, 5e-2]\n",
    "    A_dict = dict()\n",
    "    C_dict = dict()\n",
    "    for cur_sprs in sprs_ls:\n",
    "        cur_A, cur_mask, cur_norm = update_spatial(\n",
    "            Y_hw_chk,\n",
    "            A_sub,\n",
    "            C_sub,\n",
    "            sn_spatial,\n",
    "            in_memory=True,\n",
    "            dl_wnd=param_second_spatial[\"dl_wnd\"],\n",
    "            sparse_penal=cur_sprs,\n",
    "        )\n",
    "        if cur_A.sizes[\"unit_id\"]:\n",
    "            A_dict[cur_sprs] = cur_A.compute()\n",
    "            C_dict[cur_sprs] = C_sub.sel(unit_id=cur_mask).compute()\n",
    "    hv_res = visualize_spatial_update(A_dict, C_dict, kdims=[\"sparse penalty\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "hv.output(size=int(output_size * 0.6))\n",
    "if interactive:\n",
    "    display(hv_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spatial update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "</font> <font color='red'>Don't forget to update the sparse penalty parameter</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   <font color='red'> ____________________________________________________________</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "param_second_spatial['sparse_penal'] = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(colored(\"sparse_penal :\", \"light_magenta\"),  file = open(\"CON\", \"w\") )\n",
    "print(colored(param_second_spatial['sparse_penal'], \"light_magenta\"),  file = open(\"CON\", \"w\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   <font color='red'> ____________________________________________________________</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "A_new, mask, norm_fac = update_spatial(\n",
    "    Y_hw_chk, A, C, sn_spatial, **param_second_spatial\n",
    ")\n",
    "C_new = save_minian(\n",
    "    (C.sel(unit_id=mask) * norm_fac).rename(\"C_new\"), intpath, overwrite=True\n",
    ")\n",
    "C_chk_new = save_minian(\n",
    "    (C_chk.sel(unit_id=mask) * norm_fac).rename(\"C_chk_new\"), intpath, overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "b_new, f_new = update_background(Y_fm_chk, A_new, C_chk_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualization of spatial footprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "hv.output(size=int(output_size * 0.6))\n",
    "opts = dict(\n",
    "    plot=dict(height=A.sizes[\"height\"], width=A.sizes[\"width\"], colorbar=True),\n",
    "    style=dict(cmap=\"Viridis\"),\n",
    ")\n",
    "(\n",
    "    regrid(\n",
    "        hv.Image(\n",
    "            A.max(\"unit_id\").compute().astype(np.float32).rename(\"A\"),\n",
    "            kdims=[\"width\", \"height\"],\n",
    "        ).opts(**opts)\n",
    "    ).relabel(\"Spatial Footprints Last\")\n",
    "    + regrid(\n",
    "        hv.Image(\n",
    "            (A.fillna(0) > 0).sum(\"unit_id\").compute().astype(np.uint8).rename(\"A\"),\n",
    "            kdims=[\"width\", \"height\"],\n",
    "        ).opts(**opts)\n",
    "    ).relabel(\"Binary Spatial Footprints Last\")\n",
    "    + regrid(\n",
    "        hv.Image(\n",
    "            A_new.max(\"unit_id\").compute().astype(np.float32).rename(\"A\"),\n",
    "            kdims=[\"width\", \"height\"],\n",
    "        ).opts(**opts)\n",
    "    ).relabel(\"Spatial Footprints New\")\n",
    "    + regrid(\n",
    "        hv.Image(\n",
    "            (A_new > 0).sum(\"unit_id\").compute().astype(np.uint8).rename(\"A\"),\n",
    "            kdims=[\"width\", \"height\"],\n",
    "        ).opts(**opts)\n",
    "    ).relabel(\"Binary Spatial Footprints New\")\n",
    ").cols(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "A = save_minian(\n",
    "    A_new.rename(\"A\"),\n",
    "    intpath,\n",
    "    overwrite=True,\n",
    "    chunks={\"unit_id\": 1, \"height\": -1, \"width\": -1},\n",
    ")\n",
    "b = save_minian(b_new.rename(\"b\"), intpath, overwrite=True)\n",
    "f = save_minian(\n",
    "    f_new.chunk({\"frame\": chk[\"frame\"]}).rename(\"f\"), intpath, overwrite=True\n",
    ")\n",
    "C = save_minian(C_new.rename(\"C\"), intpath, overwrite=True)\n",
    "C_chk = save_minian(C_chk_new.rename(\"C_chk\"), intpath, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'> STOP 10</font> <font color='red'>second temporal update</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parameter exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "if interactive:\n",
    "    units = np.random.choice(A.coords[\"unit_id\"], 10, replace=False)\n",
    "    units.sort()\n",
    "    A_sub = A.sel(unit_id=units).persist()\n",
    "    C_sub = C_chk.sel(unit_id=units).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "#%%time\n",
    "if interactive:\n",
    "    p_ls = [1]\n",
    "    sprs_ls = [0.1, 0.5, 1, 2]\n",
    "    add_ls = [20]\n",
    "    noise_ls = [0.06]\n",
    "    YA_dict, C_dict, S_dict, g_dict, sig_dict, A_dict = [dict() for _ in range(6)]\n",
    "    YrA = (\n",
    "        compute_trace(Y_fm_chk, A_sub, b, C_sub, f)\n",
    "        .persist()\n",
    "        .chunk({\"unit_id\": 1, \"frame\": -1})\n",
    "    )\n",
    "    for cur_p, cur_sprs, cur_add, cur_noise in itt.product(\n",
    "        p_ls, sprs_ls, add_ls, noise_ls\n",
    "    ):\n",
    "        ks = (cur_p, cur_sprs, cur_add, cur_noise)\n",
    "        print(\n",
    "            \"p:{}, sparse penalty:{}, additional lag:{}, noise frequency:{}\".format(\n",
    "                cur_p, cur_sprs, cur_add, cur_noise\n",
    "            )\n",
    "        )\n",
    "        cur_C, cur_S, cur_b0, cur_c0, cur_g, cur_mask = update_temporal(\n",
    "            A_sub,\n",
    "            C_sub,\n",
    "            YrA=YrA,\n",
    "            sparse_penal=cur_sprs,\n",
    "            p=cur_p,\n",
    "            use_smooth=True,\n",
    "            add_lag=cur_add,\n",
    "            noise_freq=cur_noise,\n",
    "        )\n",
    "        YA_dict[ks], C_dict[ks], S_dict[ks], g_dict[ks], sig_dict[ks], A_dict[ks] = (\n",
    "            YrA.compute(),\n",
    "            cur_C.compute(),\n",
    "            cur_S.compute(),\n",
    "            cur_g.compute(),\n",
    "            (cur_C + cur_b0 + cur_c0).compute(),\n",
    "            A_sub.compute(),\n",
    "        )\n",
    "    hv_res = visualize_temporal_update(\n",
    "        YA_dict,\n",
    "        C_dict,\n",
    "        S_dict,\n",
    "        g_dict,\n",
    "        sig_dict,\n",
    "        A_dict,\n",
    "        kdims=[\"p\", \"sparse penalty\", \"additional lag\", \"noise frequency\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "hv.output(size=int(output_size * 0.6))\n",
    "if interactive:\n",
    "    display(hv_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### temporal update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "</font> <font color='red'>Don't forget to update the sparse penalty parameter</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   <font color='red'> ____________________________________________________________</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "param_second_temporal['sparse_penal'] = 0.5\n",
    "param_second_temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(colored(\"sparse_penal :\", \"light_magenta\"),  file = open(\"CON\", \"w\") )\n",
    "print(colored(param_second_temporal['sparse_penal'], \"light_magenta\"),  file = open(\"CON\", \"w\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   <font color='red'> ____________________________________________________________</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "YrA = save_minian(\n",
    "    compute_trace(Y_fm_chk, A, b, C_chk, f).rename(\"YrA\"),\n",
    "    intpath,\n",
    "    overwrite=True,\n",
    "    chunks={\"unit_id\": 1, \"frame\": -1},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "C_new, S_new, b0_new, c0_new, g, mask = update_temporal(\n",
    "    A, C, YrA=YrA, **param_second_temporal\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "hv.output(size=int(output_size * 0.6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualization of accepted units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "hv.output(size=int(output_size * 0.6))\n",
    "if interactive:\n",
    "    sig = C_new + b0_new + c0_new\n",
    "    display(\n",
    "        visualize_temporal_update(\n",
    "            YrA.sel(unit_id=mask),\n",
    "            C_new,\n",
    "            S_new,\n",
    "            g,\n",
    "            sig,\n",
    "            A.sel(unit_id=mask),\n",
    "        )\n",
    "    )\n",
    "print(colored(\"______ COMPUTATIONS DONE ______\", \"yellow\"), file = open(\"CON\", \"w\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "C = save_minian(\n",
    "    C_new.rename(\"C\").chunk({\"unit_id\": 1, \"frame\": -1}), intpath, overwrite=True\n",
    ")\n",
    "C_chk = save_minian(\n",
    "    C.rename(\"C_chk\"),\n",
    "    intpath,\n",
    "    overwrite=True,\n",
    "    chunks={\"unit_id\": -1, \"frame\": chk[\"frame\"]},\n",
    ")\n",
    "S = save_minian(\n",
    "    S_new.rename(\"S\").chunk({\"unit_id\": 1, \"frame\": -1}), intpath, overwrite=True\n",
    ")\n",
    "b0 = save_minian(\n",
    "    b0_new.rename(\"b0\").chunk({\"unit_id\": 1, \"frame\": -1}), intpath, overwrite=True\n",
    ")\n",
    "c0 = save_minian(\n",
    "    c0_new.rename(\"c0\").chunk({\"unit_id\": 1, \"frame\": -1}), intpath, overwrite=True\n",
    ")\n",
    "A = A.sel(unit_id=C.coords[\"unit_id\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## playing around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "for idx in A_init[\"unit_id\"].values:\n",
    "    print('unit number is %d with height %d and width %d'% (idx,np.argmax(np.sum(A_init.sel(unit_id  =idx).values,1)),np.argmax(np.sum(A_init.sel(unit_id  = idx).values,0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(7, 15)) \n",
    "for idx in C[\"unit_id\"].values:\n",
    "    color = 'palevioletred'\n",
    "    if idx % 2 : \n",
    "        color = 'purple'\n",
    "    plt.plot(C.sel( unit_id = idx) + 10*idx, color)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Units')\n",
    "plt.gca().spines['top'].set_visible(False)  # Hides the top spine\n",
    "plt.gca().spines['right'].set_visible(False)  # Hides the right spine\n",
    "plt.gca().xaxis.set_ticks([])\n",
    "plt.gca().set_xticklabels([]) \n",
    "plt.savefig(os.path.join(result_path, session_name, \"C.png\"), format=\"png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "fig, ax = plt.subplots()\n",
    "fig.figsize=(7, 15)\n",
    "im = ax.imshow(S, aspect = 'auto', cmap = 'binary')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Units')\n",
    "plt.gca().spines['top'].set_visible(False)  # Hides the top spine\n",
    "plt.gca().spines['right'].set_visible(False)  # Hides the right spine\n",
    "plt.gca().xaxis.set_ticks([])\n",
    "plt.gca().set_xticklabels([])\n",
    "plt.savefig(os.path.join(result_path, session_name, \"S.png\"), format=\"png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "order = np.argsort(np.argmax(C.values,1))\n",
    "fig, ax = plt.subplots()\n",
    "fig.figsize=(7, 15)\n",
    "im = ax.imshow(S.values[order], aspect = 'auto', cmap = 'binary')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Units')\n",
    "plt.gca().spines['top'].set_visible(False)  # Hides the top spine\n",
    "plt.gca().spines['right'].set_visible(False)  # Hides the right spine\n",
    "plt.gca().xaxis.set_ticks([])\n",
    "plt.gca().set_xticklabels([])\n",
    "plt.savefig(os.path.join(result_path, session_name, \"S_ordered.png\"), format=\"png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "plt.figure(figsize=(7, 15)) \n",
    "i = 0 \n",
    "\n",
    "for idx in C.unit_id.values[order]:\n",
    "    i = i+1\n",
    "    color = 'teal'\n",
    "    if i % 2 : \n",
    "        color = 'darkseagreen'\n",
    "    plt.plot(C.sel( unit_id = idx) - 10*i, color)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Units')\n",
    "plt.gca().spines['top'].set_visible(False)  # Hides the top spine\n",
    "plt.gca().spines['right'].set_visible(False)  # Hides the right spine\n",
    "plt.gca().xaxis.set_ticks([])\n",
    "plt.gca().set_xticklabels([])\n",
    "plt.savefig(os.path.join(result_path, session_name, \"C_ordered.png\"), format=\"png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "generate_videos(varr.sel(subset), Y_fm_chk, A=A, C=C_chk, vpath=param_save_minian['dpath'])#dpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#%%time\n",
    "if interactive:\n",
    "    cnmfviewer = CNMFViewer(A=A, C=C, S=S, org=Y_fm_chk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "hv.output(size=int(output_size * 0.35))\n",
    "if interactive:\n",
    "    display(cnmfviewer.show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save unit labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "tutorial"
    ]
   },
   "source": [
    "If manual manipulation of `unit_labels` are done during visualization, we should assign them as coordinates to our final results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_cell\n",
    "if interactive:\n",
    "    A = A.assign_coords(unit_labels=(\"unit_id\", cnmfviewer.unit_labels.data))\n",
    "    C = C.assign_coords(unit_labels=(\"unit_id\", cnmfviewer.unit_labels.data))\n",
    "    S = S.assign_coords(unit_labels=(\"unit_id\", cnmfviewer.unit_labels.data))\n",
    "    c0 = c0.assign_coords(unit_labels=(\"unit_id\", cnmfviewer.unit_labels.data))\n",
    "    b0 = b0.assign_coords(unit_labels=(\"unit_id\", cnmfviewer.unit_labels.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save final results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "tutorial"
    ]
   },
   "source": [
    "Finally we commit to saving final results using `param_save_minian`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "A = save_minian(A.rename(\"A\"), **param_save_minian)\n",
    "C = save_minian(C.rename(\"C\"), **param_save_minian)\n",
    "S = save_minian(S.rename(\"S\"), **param_save_minian)\n",
    "c0 = save_minian(c0.rename(\"c0\"), **param_save_minian)\n",
    "b0 = save_minian(b0.rename(\"b0\"), **param_save_minian)\n",
    "b = save_minian(b.rename(\"b\"), **param_save_minian)\n",
    "f = save_minian(f.rename(\"f\"), **param_save_minian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "# Assume A, C, S, c0, b, b0, f, YrA, unit_id, unit_labels, max_proj, motion are xarray.DataArray objects\n",
    "\n",
    "# Create an xarray Dataset from multiple xarray DataArrays\n",
    "ds = xr.Dataset({\n",
    "    \"A\": A,  \n",
    "    \"C\": C,  \n",
    "    \"S\": S,  \n",
    "    \"c0\": c0,  \n",
    "    \"b\": b,  \n",
    "    \"b0\": b0,  \n",
    "    \"f\": f,  \n",
    "    \"YrA\": YrA,  \n",
    "    \"unit_id\": C.unit_id,  \n",
    "    \"unit_labels\": cnmfviewer.unit_labels,  \n",
    "    \"max_proj\": max_proj,  \n",
    "    \"motion\": motion  \n",
    "})\n",
    "\n",
    "# Save dataset to a NetCDF file\n",
    "ds.to_netcdf(os.path.join(minian_ds_path,\"minian_dataset.nc\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Define your parameters as a dictionary\n",
    "parameters = {\n",
    "    \"ksize\": param_denoise[\"ksize\"] ,\n",
    "    \"wnd\": param_background_removal[\"wnd\"],\n",
    "    \"noise_freq\": param_pnr_refine[\"noise_freq\"],\n",
    "    \"thres\": param_pnr_refine[\"thres\"],\n",
    "    \"thres_dist\": param_seeds_merge['thres_dist'],\n",
    "    \"spatial_sparse_penal1\": param_first_spatial['sparse_penal'],\n",
    "    \"temp_sparse_penal1\": param_first_temporal['sparse_penal'],\n",
    "    \"spatial_sparse_penal2\": param_second_spatial['sparse_penal'],\n",
    "    \"temp_sparse_penal2\": param_second_temporal['sparse_penal']\n",
    "}\n",
    "\n",
    "\n",
    "# Save to a JSON file\n",
    "with open(param_file, \"w\") as file:\n",
    "    json.dump(parameters, file, indent=4)\n",
    "with open(os.path.join(minian_ds_path, \"session_used_parameters.json\"), \"w\") as file:\n",
    "    json.dump(parameters, file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(colored(\"______ RESULTS SAVED ______\", \"light_green\"), file = open(\"CON\", \"w\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## close cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C.to_netcdf(os.path.join(minian_ds_path, \"C.nc\"))\n",
    "S.to_netcdf(os.path.join(minian_ds_path, \"S.nc\"))\n",
    "A.to_netcdf(os.path.join(minian_ds_path, \"A.nc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "name": "pipeline.ipynb",
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
